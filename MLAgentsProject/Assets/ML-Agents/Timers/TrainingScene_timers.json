{"count":1,"self":59.1966848,"total":61.498574899999994,"children":{"InitializeActuators":{"count":20,"self":0,"total":0,"children":null},"InitializeSensors":{"count":20,"self":0.0040774999999999995,"total":0.0040774999999999995,"children":null},"AgentSendState":{"count":2801,"self":1.1145464,"total":1.9946392,"children":{"CollectObservations":{"count":14020,"self":0.1292379,"total":0.1292379,"children":null},"WriteActionMask":{"count":14020,"self":0.0212329,"total":0.0212329,"children":null},"RequestDecision":{"count":14020,"self":0.55853,"total":0.729622,"children":{"RayPerceptionSensor.Perceive":{"count":14020,"self":0.171092,"total":0.171092,"children":null}}}}},"DecideAction":{"count":2801,"self":0.1192244,"total":0.1192244,"children":null},"AgentAct":{"count":2801,"self":0.18395119999999998,"total":0.18395119999999998,"children":{"RayPerceptionSensor.Perceive":{"count":1,"self":0,"total":0,"children":null}}},"RayPerceptionSensor.Perceive":{"count":28,"self":0,"total":0,"children":null}},"gauges":{"WanderingAgent.CumulativeReward":{"count":29,"max":-237.562057,"min":-1000.8999,"runningAverage":-974.0827,"value":-1000.09607,"weightedAverage":-985.9626}},"metadata":{"timer_format_version":"0.1.0","start_time_seconds":"1723973494","unity_version":"6000.0.15f1","command_line_arguments":"C:\\Program Files\\Unity\\Hub\\Editor\\6000.0.15f1\\Editor\\Unity.exe -projectpath C:\\Users\\3nigma\\source\\repos\\MLAgentsProject -useHub -hubIPC -cloudEnvironment production","communication_protocol_version":"1.5.0","com.unity.ml-agents_version":"3.0.0-exp.1","scene_name":"TrainingScene","end_time_seconds":"1723973556"}}